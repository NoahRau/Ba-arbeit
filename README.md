# State-of-the-Art Hybrid Ontology Matching Pipeline

A modern, modular implementation of ontology matching combining multiple complementary strategies for maximum precision and recall.

## ğŸ¯ Overview

This project implements a 4-stage hybrid pipeline for ontology alignment between S1000D technical documentation and OWL ontologies:

1. **Candidate Generation**: KROMA (DMC-based) + DeepOnto (BERT semantic) + String matching
2. **Aggregation**: Weighted rank fusion combining complementary signals
3. **LLM Reranking**: Claude Sonnet 4.5 for intelligent final selection
4. **Validation**: Optional post-processing and validation

## ğŸ“ Project Structure

```
BA-arbeit/
â”œâ”€â”€ src/                          # Source code modules
â”‚   â”œâ”€â”€ matchers/                 # Matching algorithms
â”‚   â”‚   â”œâ”€â”€ base_matcher.py      # Abstract matcher interface
â”‚   â”‚   â”œâ”€â”€ kroma_matcher.py     # DMC-based heuristic matcher
â”‚   â”‚   â”œâ”€â”€ deeponto_matcher.py  # BERT semantic matcher
â”‚   â”‚   â”œâ”€â”€ string_matcher.py    # String similarity baseline
â”‚   â”‚   â””â”€â”€ aml_matcher.py       # AML wrapper (experimental)
â”‚   â”œâ”€â”€ aggregation/             # Score aggregation
â”‚   â”‚   â””â”€â”€ weighted_aggregator.py
â”‚   â”œâ”€â”€ reranking/               # LLM reranking
â”‚   â”‚   â””â”€â”€ llm_reranker.py
â”‚   â”œâ”€â”€ pipeline/                # Main pipeline orchestration
â”‚   â”‚   â””â”€â”€ hybrid_pipeline.py
â”‚   â”œâ”€â”€ evaluation/              # Evaluation utilities
â”‚   â”‚   â””â”€â”€ kroma_evaluation.py
â”‚   â”œâ”€â”€ validation/              # Validation logic (placeholder)
â”‚   â””â”€â”€ data_loader.py           # Data loading with hierarchical context
â”‚
â”œâ”€â”€ scripts/                      # Executable scripts
â”‚   â”œâ”€â”€ generate_matches_for_annotation.py
â”‚   â”œâ”€â”€ evaluate_annotated_matches.py
â”‚   â”œâ”€â”€ create_gold_standard.py
â”‚   â””â”€â”€ run_benchmark.py
â”‚
â”œâ”€â”€ data/                         # Data files
â”‚   â”œâ”€â”€ s1000d/                  # S1000D XML files
â”‚   â”œâ”€â”€ ontologies/              # OWL ontology files
â”‚   â””â”€â”€ results/                 # Generated matches and evaluations
â”‚
â”œâ”€â”€ cache/                        # Cache files
â”‚   â”œâ”€â”€ embeddings/              # BERT embeddings cache
â”‚   â””â”€â”€ logs/                    # Execution logs
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ ANNOTATION_GUIDE.md      # Manual annotation instructions
â”‚   â”œâ”€â”€ DEMO_EVALUATION_REPORT.md
â”‚   â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md
â”‚   â”œâ”€â”€ QUICK_START.md
â”‚   â””â”€â”€ REFACTORING_PLAN.md
â”‚
â”œâ”€â”€ legacy/                       # Old implementation (archived)
â”œâ”€â”€ tools/                        # External tools (AML)
â”œâ”€â”€ app.py                        # Main application entry point
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file
```

## ğŸš€ Quick Start

### Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd BA-arbeit
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Set up your Claude API key (for LLM reranking):
```bash
export ANTHROPIC_API_KEY="your-api-key-here"
```

### Generate Matches for Annotation

Run the hybrid pipeline on all S1000D concepts:

```bash
python scripts/generate_matches_for_annotation.py
```

This generates `data/results/hybrid_pipeline_matches.csv` with:
- Pipeline's selected matches
- Top-5 candidates for each concept
- Confidence scores and methods used

### Manual Annotation

1. Open `data/results/hybrid_pipeline_matches.csv`
2. Fill in the `is_match_manual` column (TRUE/FALSE)
3. See `docs/ANNOTATION_GUIDE.md` for detailed instructions
4. Save as `data/results/hybrid_pipeline_matches_ANNOTATED.csv`

### Evaluate Results

After manual annotation, compute metrics:

```bash
python scripts/evaluate_annotated_matches.py data/results/hybrid_pipeline_matches_ANNOTATED.csv --plot
```

This generates:
- Evaluation report (Markdown) with Precision, Recall, F1, MCC
- Confusion matrix visualization
- Error analysis (false positives/negatives)
- Metrics JSON file

## ğŸ§© Core Components

### 1. Matchers

#### KROMA Matcher (`src/matchers/kroma_matcher.py`)
- Exploits S1000D DMC structure (chapter codes)
- Hierarchical component matching
- Domain-specific heuristics
- **Weight**: 0.4 (highest)

#### DeepOnto Matcher (`src/matchers/deeponto_matcher.py`)
- ModernBERT embeddings (8192 token context)
- Subsumption filtering (parent-child not a match)
- Sibling detection
- Hierarchical context integration
- **Weight**: 0.35

#### String Matcher (`src/matchers/string_matcher.py`)
- Jaccard similarity (token overlap)
- Edit distance (sequence similarity)
- Context-aware scoring
- **Weight**: 0.25

### 2. Aggregation (`src/aggregation/weighted_aggregator.py`)

Combines matcher outputs using:
- **Rank Fusion (RRF)**: Reciprocal Rank Fusion for robust aggregation
- **Weighted Sum**: Direct score combination (alternative)

### 3. LLM Reranking (`src/reranking/llm_reranker.py`)

- Model: Claude Sonnet 4.5
- Listwise evaluation of top-5 candidates
- German language prompts
- Conservative threshold (0.95 confidence)
- NULL support for "no good match"

### 4. Pipeline (`src/pipeline/hybrid_pipeline.py`)

Orchestrates all stages:
```python
from src.pipeline.hybrid_pipeline import HybridPipeline
from src.data_loader import load_all_concepts

# Load data
df = load_all_concepts()
s1000d_df = df[df['source'] == 's1000d']
ontology_df = df[df['source'] == 'bike_ontology']

# Initialize pipeline
pipeline = HybridPipeline(
    s1000d_df,
    ontology_df,
    use_llm=True,
    aggregation_method='rank_fusion'
)

# Match a concept
result = pipeline.match_concept(source_concept, top_k=5)
```

## ğŸ“Š Performance

**Current results** (on 56 S1000D concepts):
- **Precision**: 88.89% (8 TP, 1 FP)
- **Recall**: 61.54% (8 TP, 5 FN)
- **F1-Score**: 72.73%
- **MCC**: 0.690

The pipeline prioritizes **precision over recall** - better to miss a match than create a wrong one.

## ğŸ”§ Configuration

### Matcher Weights

Edit `src/aggregation/weighted_aggregator.py`:
```python
self.weights = {
    'kroma': 0.4,      # DMC-based heuristics
    'deeponto': 0.35,  # BERT semantic
    'string': 0.25     # String similarity
}
```

### LLM Confidence Threshold

Edit `src/reranking/llm_reranker.py`:
```python
self.confidence_threshold = 0.95  # Lower = more matches
```

### Top-K Candidates

Edit pipeline calls:
```python
pipeline.match_concept(concept, top_k=5)  # Number of candidates
```

## ğŸ“š Documentation

- **[Quick Start](docs/QUICK_START.md)**: Get started quickly
- **[Annotation Guide](docs/ANNOTATION_GUIDE.md)**: Manual annotation instructions
- **[Implementation Summary](docs/IMPLEMENTATION_SUMMARY.md)**: Technical details
- **[Refactoring Plan](docs/REFACTORING_PLAN.md)**: Architecture decisions

## ğŸ§ª Testing

Run evaluation on KROMA matcher:
```bash
python src/evaluation/kroma_evaluation.py
```

Run full benchmark:
```bash
python scripts/run_benchmark.py
```

## ğŸ” Data Format

### S1000D XML Structure
```xml
<dmodule>
  <identAndStatusSection>
    <dmAddress>
      <dmIdent>
        <dmCode>DMC-S1000DBIKE-AAA-DA0-10-10-00AA-921A-A</dmCode>
      </dmIdent>
    </dmAddress>
  </identAndStatusSection>
  <content>...</content>
</dmodule>
```

### OWL Ontology
BikeOntology from: https://giuliamenna.github.io/BikeOntology/

Classes with hierarchical structure:
- `owl:Class` with `rdfs:subClassOf` relationships
- Named individuals with `rdf:type` assertions

## ğŸ› ï¸ Development

### Adding a New Matcher

1. Create `src/matchers/my_matcher.py`:
```python
from src.matchers.base_matcher import BaseMatcher

class MyMatcher(BaseMatcher):
    def find_candidates(self, source_concept, top_k=10):
        # Your matching logic
        return [(uri, score), ...]

    def batch_match(self, source_concepts, top_k=10):
        # Batch implementation
        return {uri: candidates, ...}
```

2. Register in `src/pipeline/hybrid_pipeline.py`
3. Add weight in `src/aggregation/weighted_aggregator.py`

### Running Tests

```bash
# Test data loader
python -c "from src.data_loader import load_all_concepts; print(load_all_concepts())"

# Test pipeline
python -c "from src.pipeline.hybrid_pipeline import HybridPipeline; help(HybridPipeline)"
```

## ğŸ“¦ Dependencies

Key packages:
- `deeponto>=0.9.0` - DeepOnto framework
- `sentence-transformers` - ModernBERT embeddings
- `anthropic>=0.40.0` - Claude API
- `owlready2>=0.46` - OWL processing
- `scikit-learn` - Evaluation metrics
- `pandas`, `numpy` - Data manipulation

See `requirements.txt` for full list.

## ğŸ¤ Contributing

This is a research project for ontology matching. For improvements:

1. Create a new branch
2. Make your changes
3. Test thoroughly
4. Document changes in `docs/`

## ğŸ“„ License

Academic research project - see LICENSE file.

## ğŸ™ Acknowledgments

- **DeepOnto Framework**: Oxford/Manchester (https://github.com/KRR-Oxford/DeepOnto)
- **BikeOntology**: Giulia Menna (https://giuliamenna.github.io/BikeOntology/)
- **S1000D Standard**: ASD specification for technical documentation
- **Claude API**: Anthropic for LLM capabilities

## ğŸ“§ Contact

For questions or issues, please open an issue on GitHub.

---

**Last Updated**: 2026-01-08
